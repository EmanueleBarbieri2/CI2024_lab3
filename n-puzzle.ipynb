{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "# Define an action as swapping two positions\n",
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all valid moves for the blank tile\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "# Apply an action to transition to a new state\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "# Check if the puzzle is solvable\n",
    "def is_solvable(state: np.ndarray) -> bool:\n",
    "    flat_state = state.flatten()\n",
    "    inversions = sum(\n",
    "        1\n",
    "        for i in range(len(flat_state))\n",
    "        for j in range(i + 1, len(flat_state))\n",
    "        if flat_state[i] > flat_state[j] > 0\n",
    "    )\n",
    "    blank_row = PUZZLE_DIM - np.where(state == 0)[0][0]\n",
    "    if PUZZLE_DIM % 2 == 1:\n",
    "        return inversions % 2 == 0\n",
    "    else:\n",
    "        if blank_row % 2 == 0:\n",
    "            return inversions % 2 == 1\n",
    "        else:\n",
    "            return inversions % 2 == 0\n",
    "\n",
    "# Manhattan distance heuristic\n",
    "def hn(state: np.ndarray) -> int:\n",
    "    h = 0\n",
    "    for i in range(PUZZLE_DIM):\n",
    "        for j in range(PUZZLE_DIM):\n",
    "            if state[i, j] != 0:\n",
    "                x, y = divmod(state[i, j] - 1, PUZZLE_DIM)\n",
    "                h += abs(x - i) + abs(y - j)\n",
    "    return h  \n",
    "\n",
    "while True:\n",
    "    RANDOMIZE_STEPS = 100_000\n",
    "    state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "    for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "        state = do_action(state, choice(available_actions(state)))\n",
    "    if is_solvable(state):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution based on A* search\n",
    "def astar_search(state: np.ndarray) -> None:\n",
    "    goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "    print(\"Initial state:\")\n",
    "    print(state, \"\\n\")\n",
    "    quality = 0\n",
    "    g = 0\n",
    "\n",
    "    open_list = [] # Priority queue\n",
    "    state_tuple = tuple(state.flatten()) \n",
    "    heapq.heappush(open_list, (0, state_tuple))\n",
    "    visited = set() # Visited states\n",
    "\n",
    "    while open_list:\n",
    "        f, state_tuple = heapq.heappop(open_list) \n",
    "        current_state = np.array(state_tuple).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "        goal_state = np.array(goal_state).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "        if np.array_equal(current_state, goal_state): # If goal state is equal to current state end loop\n",
    "            eff = quality / g\n",
    "            print(\"Final state:\")\n",
    "            print(current_state)\n",
    "            print(f'Cost: {g}, Quality: {quality}, Efficiency: {eff}')\n",
    "            return\n",
    "\n",
    "        if state_tuple in visited:\n",
    "            continue\n",
    "        visited.add(state_tuple) # Mark the current state as visited\n",
    "        quality += 1\n",
    "\n",
    "        for action in available_actions(current_state): #Cosider all possible actions\n",
    "            new_state = do_action(current_state, action)\n",
    "            new_state_tuple = tuple(new_state.flatten()) \n",
    "            if new_state_tuple in visited:\n",
    "                continue\n",
    "\n",
    "            g = g + 1  \n",
    "            h = hn(new_state)  \n",
    "            f = g + h \n",
    "            heapq.heappush(open_list, (f, new_state_tuple))\n",
    "\n",
    "# Not converting np.array to tuple for the state, causes errors as it is not hashable.\n",
    "    # Credits for np.array -> tuple conversion in while loop: https://www.redblobgames.com/pathfinding/a-star/implementation.html\n",
    "# Solve\n",
    "astar_search(state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
